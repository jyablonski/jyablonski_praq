{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAP4RcQEAAAAAmnEvBgpDVLLw5wM9uYeTZqxxYDM%3DxFIva9YOzJH5A8RKIhGZVzCllL1njWDLbeNlSlQr05CqoTZD3C',\n",
       " 'endpoint': 'https://api.twitter.com/2/tweets/search/recent',\n",
       " 'extra_headers_dict': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from searchtweets import load_credentials\n",
    "\n",
    "load_credentials(filename=\".twitter_keys.yaml\",\n",
    "                 yaml_key=\"search_tweets_v2\",\n",
    "                 env_overwrite=False)\n",
    "\n",
    "# they like, want you to call python scripts from the terminal?  and save them locally ?  what the fuck ?\n",
    "# searchtweets-v2 sucks ass don't fuckingbother with this nonsense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, load_credentials, gen_request_parameters\n",
    "\n",
    "search_args = load_credentials(filename=\".twitter_keys.yaml\",\n",
    "                 yaml_key=\"search_tweets_v2\",\n",
    "                 env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\":\"nba\",\"max_results\":100}\n"
     ]
    }
   ],
   "source": [
    "query = gen_request_parameters(\"nba\", results_per_call=100, granularity=None)\n",
    "print(query)\n",
    "# this is generating the framework of the query we want\n",
    "# 2 ways to go from here.\n",
    "# quick method to collect small amount of tweets to memory\n",
    "# or use ResultStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import collect_results\n",
    "\n",
    "tweets = collect_results(query,\n",
    "                         max_tweets=100,\n",
    "                         result_stream_args=search_args) # change this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @IndianaFever: watch us on @BallySportsIN! ðŸ“º\\n\\nðŸ”— https://t.co/zaqAkiL5Za\\n\\n#FeverIgnite https://t.co/yXgnyJb2iz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]['data'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(request_parameters=query,\n",
    "                max_results=500,\n",
    "                max_pages=1,\n",
    "                **search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultStream: \n",
      "\t{\n",
      "    \"endpoint\":\"https:\\/\\/api.twitter.com\\/2\\/tweets\\/search\\/recent\",\n",
      "    \"request_parameters\":{\n",
      "        \"query\":\"nba\",\n",
      "        \"max_results\":100\n",
      "    },\n",
      "    \"max_tweets\":500\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(rs.stream())\n",
    "# each element inthis list has 100 tweets in it, up to 500.\n",
    "# [print(tweet) for tweet in tweets[0:10]]\n",
    "# this is a complete fucking piece ofshit api jesus fucking christ dude.\n",
    "# youg et literally no data outside of an id column and the raw text which has a bunch of RT bullshit in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rule = gen_request_parameters(\"nba\", granularity=\"day\")\n",
    "\n",
    "counts = collect_results(count_rule, result_stream_args=search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = pd.json_normalize(tweets[0]['data'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51acfa6005ffec5e74e71d844e0daa05d24ac78244a0bb1b7874b497027552e7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
