{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import praw\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import exc, create_engine\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import twint\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "today = datetime.now().date()\n",
    "todaytime = datetime.now()\n",
    "yesterday = today - timedelta(1)\n",
    "day = (datetime.now() - timedelta(1)).day\n",
    "month = (datetime.now() - timedelta(1)).month\n",
    "year = (datetime.now() - timedelta(1)).year\n",
    "if today < datetime(2022, 4, 11).date():\n",
    "    season_type = \"Regular Season\"\n",
    "elif (today >= datetime(2022, 4, 11).date()) & (today < datetime(2022, 4, 16).date()):\n",
    "    season_type = \"Play-In\"\n",
    "else:\n",
    "    season_type = \"Playoffs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_sql(con, data, table_type):\n",
    "    \"\"\"\n",
    "    SQL Table function to write a pandas data frame in aws_dfname_source format\n",
    "    Args:\n",
    "        data: The Pandas DataFrame to store in SQL\n",
    "        table_type: Whether the table should replace or append to an existing SQL Table under that name\n",
    "    Returns:\n",
    "        Writes the Pandas DataFrame to a Table in Snowflake in the {nba_source} Schema we connected to.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_name = [k for k, v in globals().items() if v is data][0]\n",
    "        # ^ this disgusting monstrosity is to get the name of the -fucking- dataframe lmfao\n",
    "        if len(data) == 0:\n",
    "            logging.info(f\"{data_name} is empty, not writing to SQL\")\n",
    "        else:\n",
    "            data.to_sql(\n",
    "                con=con,\n",
    "                name=f\"aws_{data_name}_source\",\n",
    "                index=False,\n",
    "                if_exists=table_type,\n",
    "            )\n",
    "            logging.info(f\"Writing aws_{data_name}_source to SQL\")\n",
    "    except BaseException as error:\n",
    "        logging.error(f\"SQL Write Script Failed, {error}\")\n",
    "        return error\n",
    "\n",
    "def sql_connection(rds_schema: str):\n",
    "    \"\"\"\n",
    "    SQL Connection function connecting to my postgres db with schema = nba_source where initial data in ELT lands\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        SQL Connection variable to schema: nba_source in my PostgreSQL DB\n",
    "    \"\"\"\n",
    "    RDS_USER = os.environ.get(\"RDS_USER\")\n",
    "    RDS_PW = os.environ.get(\"RDS_PW\")\n",
    "    RDS_IP = os.environ.get(\"IP\")\n",
    "    RDS_DB = os.environ.get(\"RDS_DB\")\n",
    "    try:\n",
    "        connection = create_engine(\n",
    "            f\"postgresql+psycopg2://{RDS_USER}:{RDS_PW}@{RDS_IP}:5432/{RDS_DB}\",\n",
    "            connect_args={\"options\": f\"-csearch_path={rds_schema}\"},\n",
    "            # defining schema to connect to\n",
    "            echo=False,\n",
    "        )\n",
    "        logging.info(f\"SQL Connection to schema: {rds_schema} Successful\")\n",
    "        return connection\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logging.error(f\"SQL Connection to schema: {rds_schema} Failed, Error: {e}\")\n",
    "        return e\n",
    "\n",
    "conn = sql_connection(os.environ.get(\"RDS_SCHEMA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contracts():\n",
    "    df = pd.read_html('https://www.basketball-reference.com/contracts/players.html', header = 1)[0]\n",
    "    df = df.rename(columns={df.columns[2]: 'team', df.columns[3]: 'season_salary'})\n",
    "    df = df[['Player', 'team', 'season_salary']]\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.query('season_salary != \"Salary\" & season_salary != \"2021-22\"').reset_index()\n",
    "    df['season_salary'] = df['season_salary'].str.replace(',', \"\", regex = True)\n",
    "    df['season_salary'] = df['season_salary'].str.replace('$', \"\", regex = True)\n",
    "    df['team'] = df['team'].str.replace(\"PHO\", \"PHX\")\n",
    "    df['team'] = df['team'].str.replace(\"CHO\", \"CHA\")\n",
    "    df['team'] = df['team'].str.replace(\"BRK\", \"BKN\")\n",
    "    df['season_salary'] = pd.to_numeric(df['season_salary'])\n",
    "    df['player'] = df['player'].str.normalize('NFKD').str.encode('ascii', errors = 'ignore').str.decode('utf-8')\n",
    "    df['player'] = df['player'].str.replace(\" Jr.\", \"\", regex = True)\n",
    "    df['player'] = df['player'].str.replace(\" Sr.\", \"\", regex = True)\n",
    "    df['player'] = df['player'].str.replace(\" II\", \"\", regex = True)\n",
    "    df['player'] = df['player'].str.replace(\" III\", \"\", regex = True)\n",
    "    df['player'] = df['player'].str.replace(\" IV\", \"\", regex = True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    return(df)\n",
    "\n",
    "contracts = get_contracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts.to_sql(con = conn, name = \"aws_contracts_source\", if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule Function Completed for october, retrieving 93 rows\n",
      "Schedule Function Completed for november, retrieving 318 rows\n",
      "Schedule Function Completed for december, retrieving 527 rows\n",
      "Schedule Function Completed for january, retrieving 758 rows\n",
      "Schedule Function Completed for february, retrieving 921 rows\n",
      "Schedule Function Completed for march, retrieving 1150 rows\n",
      "Schedule Function Completed for april, retrieving 1230 rows\n"
     ]
    }
   ],
   "source": [
    "def schedule_scraper(month):\n",
    "    try:\n",
    "        global schedule_df\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_2022_games-{month}.html\"\n",
    "        html = requests.get(url).content\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        headers = [th.getText() for th in soup.findAll('tr')[0].findAll('th')]\n",
    "        headers[6] = 'boxScoreLink'\n",
    "        headers[7] = 'isOT'\n",
    "        headers = headers[1:]\n",
    "\n",
    "        rows = soup.findAll('tr')[1:]\n",
    "        date_info = [[th.getText() for th in rows[i].findAll('th')]\n",
    "                for i in range(len(rows))]\n",
    "\n",
    "        game_info = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                for i in range(len(rows))]\n",
    "        date_info = [i[0] for i in date_info]\n",
    "\n",
    "        schedule = pd.DataFrame(game_info, columns = headers)\n",
    "        schedule['Date'] = date_info\n",
    "\n",
    "        schedule_df = schedule_df.append(schedule)\n",
    "        logging.info(f'Schedule Function Completed for {month}, retrieving {len(schedule_df)} rows')\n",
    "        print(f'Schedule Function Completed for {month}, retrieving {len(schedule_df)} rows')\n",
    "    except BaseException as e:\n",
    "        logging.info(f\"Schedule Scraper Function Failed, {e}\")\n",
    "        print(f\"Schedule Scraper Function Failed, {e}\")\n",
    "        df = []\n",
    "        return(df)\n",
    "\n",
    "month_list = ['october', 'november', 'december', 'january', 'february', 'march', 'april']\n",
    "schedule_df = pd.DataFrame()\n",
    "for month in month_list:\n",
    "    schedule_scraper(month)\n",
    "\n",
    "schedule_df = schedule_df[['Start (ET)', 'Visitor/Neutral', 'Home/Neutral', 'Date']]\n",
    "schedule_df['proper_date'] = pd.to_datetime(schedule_df['Date']).dt.date\n",
    "schedule_df.columns = schedule_df.columns.str.lower()\n",
    "schedule_df = schedule_df.rename(columns = {\"start (et)\": \"start_time\", \"visitor/neutral\": \"away_team\", \"home/neutral\": \"home_team\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule Function Completed for april, retrieving 80 rows\n",
      "may currently has no data in basketball-reference, stopping the function and returning data for april\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "# month_list_df = ['april', 'may', 'june']\n",
    "def schedule_scraper(year: str, month_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Web Scrape Function to scrape Schedule data by iterating through a list of months\n",
    "\n",
    "    Args:\n",
    "        year (str) - The year to scrape\n",
    "\n",
    "        month_list (list) - List of full-month names to scrape\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame of Schedule Data to be stored.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        schedule_df = pd.DataFrame()\n",
    "        completed_months = []\n",
    "        for i in month_list:\n",
    "            url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{i}.html\"\n",
    "            html = requests.get(url).content\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            headers = [th.getText() for th in soup.findAll('tr')[0].findAll('th')]\n",
    "            headers[6] = 'boxScoreLink'\n",
    "            headers[7] = 'isOT'\n",
    "            headers = headers[1:]\n",
    "\n",
    "            rows = soup.findAll('tr')[1:]\n",
    "            date_info = [[th.getText() for th in rows[i].findAll('th')]\n",
    "                    for i in range(len(rows))]\n",
    "\n",
    "            game_info = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                    for i in range(len(rows))]\n",
    "            date_info = [i[0] for i in date_info]\n",
    "\n",
    "            schedule = pd.DataFrame(game_info, columns = headers)\n",
    "            schedule['Date'] = date_info\n",
    "\n",
    "            logging.info(f'Schedule Function Completed for {i}, retrieving {len(schedule)} rows')\n",
    "            print(f'Schedule Function Completed for {i}, retrieving {len(schedule)} rows')\n",
    "            completed_months.append(i)\n",
    "            schedule_df = schedule_df.append(schedule)\n",
    "        \n",
    "        schedule_df = schedule_df[['Start (ET)', 'Visitor/Neutral', 'Home/Neutral', 'Date']]\n",
    "        schedule_df['proper_date'] = pd.to_datetime(schedule_df['Date']).dt.date\n",
    "        schedule_df.columns = schedule_df.columns.str.lower()\n",
    "        schedule_df = schedule_df.rename(columns = {\"start (et)\": \"start_time\", \"visitor/neutral\": \"away_team\", \"home/neutral\": \"home_team\"})\n",
    "\n",
    "        logging.info(f\"Schedule Function Completed for {' '.join(completed_months)}, retrieving {len(schedule_df)} total rows\")\n",
    "        print(f\"Schedule Function Completed for {' '.join(completed_months)}, retrieving {len(schedule_df)} total rows\")\n",
    "        return schedule_df\n",
    "    except IndexError as index_error:\n",
    "        logging.info(f\"{i} currently has no data in basketball-reference, stopping the function and returning data for {' '.join(completed_months)}\")\n",
    "        print(f\"{i} currently has no data in basketball-reference, stopping the function and returning data for {' '.join(completed_months)}\")\n",
    "        schedule_df = schedule_df[['Start (ET)', 'Visitor/Neutral', 'Home/Neutral', 'Date']]\n",
    "        schedule_df['proper_date'] = pd.to_datetime(schedule_df['Date']).dt.date\n",
    "        schedule_df.columns = schedule_df.columns.str.lower()\n",
    "        schedule_df = schedule_df.rename(columns = {\"start (et)\": \"start_time\", \"visitor/neutral\": \"away_team\", \"home/neutral\": \"home_team\"})\n",
    "        return schedule_df\n",
    "    except BaseException as e:\n",
    "        logging.info(f\"Schedule Scraper Function Failed, {e}\")\n",
    "        print(f\"Schedule Scraper Function Failed, {e}\")\n",
    "        df = []\n",
    "        return(df)\n",
    "\n",
    "schedule_data = schedule_scraper('2022', ['april', 'may', 'june'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51acfa6005ffec5e74e71d844e0daa05d24ac78244a0bb1b7874b497027552e7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
